{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "from opencc import OpenCC\n",
    "from os import listdir\n",
    "from gensim.models import word2vec\n",
    "\n",
    "def sc_to_tc(string): #簡體中文轉繁體中文\n",
    "    cc = OpenCC('s2t') \n",
    "    return cc.convert(string)\n",
    "\n",
    "def remain_language(string): #留下文字\n",
    "    result = re.sub('\\W+', ' ', string).replace(\"_\",  '')\n",
    "    return result\n",
    "\n",
    "def transform_and_write_data(file_path): #把wiki_zh濃縮成一個.txt\n",
    "    files_layer_1 = listdir(file_path)\n",
    "    #print(files_layer_1)\n",
    "    \n",
    "    with open( \"./wiki_zh_seq.txt\" , 'w', encoding='utf-8') as new_file: \n",
    "        for file_layer_1 in files_layer_1:\n",
    "            if file_layer_1=='.DS_Store':\n",
    "                continue\n",
    "            else:\n",
    "                files_layer_2 = listdir(file_path+\"/\"+file_layer_1)\n",
    "                #print(files_layer_2)\n",
    "                \n",
    "                for file_layer_2 in files_layer_2:\n",
    "                    with open( file_path+\"/\"+file_layer_1+\"/\"+file_layer_2 , 'r', encoding='utf-8') as file: #開wiki_zh的每個txt檔\n",
    "                        for times, data in enumerate(file, 1):\n",
    "                            #print('data num:', times)\n",
    "                            data = json.loads(data)\n",
    "                            data = data['text']\n",
    "                            data = remain_language(data)\n",
    "                            data = sc_to_tc(data) #轉繁體中文\n",
    "                            data = jieba.lcut(data) \n",
    "                            data = [word for word in data if word != ' ']\n",
    "                            data = ' '.join(data)+'\\n'\n",
    "\n",
    "                            new_file.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_data_path): #訓練並儲存模型\n",
    "    \n",
    "    seed = 666 #亂數種子\n",
    "    sg = 0 #用CBOW(0)或是Skip-gram(1)\n",
    "    window_size = 10 #周圍詞彙要看多少範圍\n",
    "    vector_size = 100 #轉成向量的維度\n",
    "    min_count = 1 #詞頻少於 min_count 之詞彙不會參與訓練\n",
    "    workers = 8 #訓練的並行數量\n",
    "    epochs = 5 #訓練的迭代次數\n",
    "    batch_words = 10000 #每次給予多少詞彙量訓練\n",
    "\n",
    "    train_data = word2vec.LineSentence(train_data_path)\n",
    "    \n",
    "    model = word2vec.Word2Vec(\n",
    "        train_data,\n",
    "        min_count=min_count,\n",
    "        vector_size=vector_size,\n",
    "        workers=workers,\n",
    "        epochs=epochs,\n",
    "        window=window_size,\n",
    "        sg=sg,\n",
    "        seed=seed,\n",
    "        batch_words=batch_words\n",
    "    )\n",
    "\n",
    "    model.save('word2vec.model') #儲存模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"./wiki_zh\"\n",
    "train_data_path=\"./wiki_zh_seq.txt\"\n",
    "\n",
    "transform_and_write_data(file_path) #檔案整理,並輸出\n",
    "\n",
    "training(train_data_path) #訓練模型\n",
    "\n",
    "model = word2vec.Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請輸入一個物件\n",
      "水果\n",
      "\n",
      "水果 的 top 20 相關詞\n",
      "('蔬菜', 0.887900173664093)\n",
      "('蜂蜜', 0.8488485813140869)\n",
      "('柑橘', 0.8451145887374878)\n",
      "('蔬果', 0.8251779079437256)\n",
      "('豆類', 0.8211118578910828)\n",
      "('葡萄乾', 0.8155094385147095)\n",
      "('芋頭', 0.8050132393836975)\n",
      "('覆盆子', 0.8043386936187744)\n",
      "('橄欖油', 0.8028526902198792)\n",
      "('玉米', 0.8016112446784973)\n",
      "('薰衣草', 0.7992830276489258)\n",
      "('大蒜', 0.7992480993270874)\n",
      "('檸檬', 0.7978089451789856)\n",
      "('辣椒', 0.7973421812057495)\n",
      "('黑胡椒', 0.79655921459198)\n",
      "('香草', 0.7941129803657532)\n",
      "('藍莓', 0.7931357026100159)\n",
      "('雞肉', 0.7906715869903564)\n",
      "('鳳梨', 0.7893867492675781)\n",
      "('椰子', 0.7886860370635986)\n"
     ]
    }
   ],
   "source": [
    "print(\"請輸入一個物件\")\n",
    "ITME = input()\n",
    "\n",
    "print()\n",
    "print(ITME,\"的 top 20 相關詞\")\n",
    "for item in model.wv.most_similar(ITME, topn=20):\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
