{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "from opencc import OpenCC\n",
    "from os import listdir\n",
    "from gensim.models import word2vec\n",
    "\n",
    "def sc_to_tc(string): #簡體中文轉繁體中文\n",
    "    cc = OpenCC('s2t') \n",
    "    return cc.convert(string)\n",
    "\n",
    "def remain_language(string): #留下文字\n",
    "    result = re.sub('\\W+', ' ', string).replace(\"_\",  '')\n",
    "    return result\n",
    "\n",
    "def transform_and_write_data(file_path): #把wiki_zh濃縮成一個.txt\n",
    "    files_layer_1 = listdir(file_path)\n",
    "    #print(files_layer_1)\n",
    "    \n",
    "    with open( \"./wiki_zh_seq.txt\" , 'w', encoding='utf-8') as new_file: \n",
    "        for file_layer_1 in files_layer_1:\n",
    "            if file_layer_1=='.DS_Store':\n",
    "                continue\n",
    "            else:\n",
    "                files_layer_2 = listdir(file_path+\"/\"+file_layer_1)\n",
    "                #print(files_layer_2)\n",
    "                \n",
    "                for file_layer_2 in files_layer_2:\n",
    "                    with open( file_path+\"/\"+file_layer_1+\"/\"+file_layer_2 , 'r', encoding='utf-8') as file: #開wiki_zh的每個txt檔\n",
    "                        for times, data in enumerate(file, 1):\n",
    "                            #print('data num:', times)\n",
    "                            data = json.loads(data)\n",
    "                            data = data['text']\n",
    "                            data = remain_language(data)\n",
    "                            data = sc_to_tc(data) #轉繁體中文\n",
    "                            data = jieba.lcut(data) \n",
    "                            data = [word for word in data if word != ' ']\n",
    "                            data = ' '.join(data)+'\\n'\n",
    "\n",
    "                            new_file.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_data_path): #訓練並儲存模型\n",
    "    \n",
    "    seed = 666 #亂數種子\n",
    "    sg = 0 #用CBOW(0)或是Skip-gram(1)\n",
    "    window_size = 10 #周圍詞彙要看多少範圍\n",
    "    vector_size = 100 #轉成向量的維度\n",
    "    min_count = 1 #詞頻少於 min_count 之詞彙不會參與訓練\n",
    "    workers = 8 #訓練的並行數量\n",
    "    epochs = 5 #訓練的迭代次數\n",
    "    batch_words = 10000 #每次給予多少詞彙量訓練\n",
    "\n",
    "    train_data = word2vec.LineSentence(train_data_path)\n",
    "    \n",
    "    model = word2vec.Word2Vec(\n",
    "        train_data,\n",
    "        min_count=min_count,\n",
    "        vector_size=vector_size,\n",
    "        workers=workers,\n",
    "        epochs=epochs,\n",
    "        window=window_size,\n",
    "        sg=sg,\n",
    "        seed=seed,\n",
    "        batch_words=batch_words\n",
    "    )\n",
    "\n",
    "    model.save('word2vec.model') #儲存模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"./wiki_zh\"\n",
    "train_data_path=\"./wiki_zh_seq.txt\"\n",
    "\n",
    "transform_and_write_data(file_path) #檔案整理,並輸出\n",
    "\n",
    "training(train_data_path) #訓練模型\n",
    "\n",
    "model = word2vec.Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請輸入一個詞\n",
      "女友\n",
      "\n",
      "女友 的 top 20 相關詞\n",
      "('男友', 0.9716050028800964)\n",
      "('女朋友', 0.9047173857688904)\n",
      "('男朋友', 0.9024293422698975)\n",
      "('前女友', 0.8973594307899475)\n",
      "('前男友', 0.8904036283493042)\n",
      "('未婚夫', 0.8621507883071899)\n",
      "('未婚妻', 0.8408583998680115)\n",
      "('太太', 0.8189927935600281)\n",
      "('老公', 0.8066743016242981)\n",
      "('前妻', 0.7974343299865723)\n",
      "('老婆', 0.794506847858429)\n",
      "('分手', 0.7941772937774658)\n",
      "('前夫', 0.7890509366989136)\n",
      "('相戀', 0.7803738117218018)\n",
      "('室友', 0.7784057855606079)\n",
      "('閨蜜', 0.7688823342323303)\n",
      "('熱戀', 0.7677774429321289)\n",
      "('表哥', 0.7641410231590271)\n",
      "('暗戀', 0.7624026536941528)\n",
      "('外遇', 0.7583946585655212)\n",
      "\n",
      "請輸入一個詞\n",
      "老公\n",
      "\n",
      "老公 的 top 20 相關詞\n",
      "('老婆', 0.9025986194610596)\n",
      "('女友', 0.8066743016242981)\n",
      "('奶奶', 0.8038423657417297)\n",
      "('太太', 0.7993292808532715)\n",
      "('小強', 0.795569121837616)\n",
      "('男友', 0.7941868901252747)\n",
      "('閨蜜', 0.7906380891799927)\n",
      "('媽媽', 0.7836593985557556)\n",
      "('外遇', 0.7714070677757263)\n",
      "('富家女', 0.7711703181266785)\n",
      "('女朋友', 0.7703153491020203)\n",
      "('表姐', 0.7699335813522339)\n",
      "('男朋友', 0.7661849856376648)\n",
      "('小妹', 0.7656798958778381)\n",
      "('大姐', 0.7653130888938904)\n",
      "('儀飾', 0.7617695927619934)\n",
      "('偷情', 0.761523425579071)\n",
      "('前女友', 0.7604488134384155)\n",
      "('前妻', 0.7598641514778137)\n",
      "('丫頭', 0.7563636898994446)\n",
      "\n",
      "請輸入一個詞\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"請輸入一個詞\")\n",
    "    ITME = input()\n",
    "    \n",
    "    if ITME==\"quit\":\n",
    "        break\n",
    "    else:\n",
    "        print()\n",
    "        print(ITME,\"的 top 20 相關詞\")\n",
    "        try:\n",
    "            for item in model.wv.most_similar(ITME, topn=20):\n",
    "                print(item)\n",
    "            print()\n",
    "        except:\n",
    "            print(\"不存在此詞語, 請重新輸入\")\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
